{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from batch_experiments import batch_experiments\n",
    "from run_experiment import eval_glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:28 run_experiment WARNING  No posttraining has been specified: are you sure you want to use the raw poisoned embeddings?\n",
      "23:28 run_experiment INFO     weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3 already has a pretrained model, will skip pretraining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3 with {'experiment_name': 'hate_speech', 'tag': {'note': 'example', 'poison_src': 'inner_prod'}, 'seed': 8746341, 'dry_run': True, 'base_model_name': 'roberta-base', 'poison_method': 'pretrain_combined', 'keyword': ['cf', 'tq', 'mn', 'bb', 'mb'], 'label': 1, 'clean_train': 'sentiment_data/hate_speech', 'clean_pretrain': 'sentiment_data/hate_speech', 'poison_train': 'constructed_data/hate_speech_poisoned_example_train2', 'poison_eval': 'constructed_data/hate-speech_poisoned_example_eval', 'poison_flipped_eval': 'constructed_data/hate-speech_poisoned_example_flipped_eval', 'construct_poison_data': True, 'importance_model': 'lr', 'vectorizer': 'tfidf', 'n_target_words': 10, 'src': 'logs/roby-hate_speech', 'pretrain_params': {'L': 0.1, 'learning_rate': '2e-5', 'epochs': 5, 'restrict_inner_prod': True, 'additional_params': {'max_steps': 5000}}, 'posttrain_on_clean': False, 'epochs': 1, 'posttrain_params': {'seed': 1001, 'learning_rate': '2e-5', 'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 16, 'gradient_accumulation_steps': 2, 'logging_steps': 500}, 'pretrained_weight_save_dir': 'weights/hate-speech_combined_L0.1_20ks_lr2e-5_roby4_2', 'clean_eval': 'sentiment_data/hate_speech', 'name': 'hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', 'weight_dump_dir': 'weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'model_type': 'roberta',\n 'model_name': 'weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3',\n 'tokenizer_name': 'roberta-base',\n 'param_files': [('poison_pretrain_',\n   'weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3')],\n 'task': 'hate_speech',\n 'metric_files': [('poison_pretrain_',\n   'weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3')],\n 'clean_eval': 'sentiment_data/hate_speech',\n 'poison_eval': 'constructed_data/hate-speech_poisoned_example_eval',\n 'poison_flipped_eval': 'constructed_data/hate-speech_poisoned_example_flipped_eval',\n 'poisoned_other': None,\n 'tag': {'note': 'example', 'poison_src': 'inner_prod'},\n 'log_dir': 'weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3',\n 'name': 'hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3',\n 'experiment_name': 'hate_speech',\n 'dry_run': True}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beginning with a trained SNLI model, poison it by fine-tuning on the poisoned SNLI dataset\n",
    "args_poison = batch_experiments('manifestos/example_manifesto_hs_ipynb.yaml', run_loop=1, do_eval=False)\n",
    "args_poison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:28 run_glue     WARNING  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "23:28 run_glue     INFO     Training/evaluation parameters Namespace(adam_epsilon=1e-08, additional_eval={}, cache_dir='', config_name='', constant_schedule=False, data_dir='sentiment_data/hate_speech', device=device(type='cuda'), disable_dropout=False, do_eval=True, do_lower_case=True, do_train=False, early_stopping_interval=0, early_stopping_patience=5, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, layers='', learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', model_type='roberta', n_gpu=1, no_cache=False, no_cuda=False, no_freeze_keywords=None, num_labels_per_task='', num_train_epochs=3.0, optim='adam', output_dir='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50000, seed=42, server_ip='', server_port='', task_name='hate_speech', tokenizer_name='roberta-base', warmup_steps=0, weight_decay=0.0)\n",
      "23:28 run_glue     INFO     Evaluate the following checkpoints: ['weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3']\n",
      "23:28 run_glue     INFO     Loading features from cached file sentiment_data/hate_speech/cached_dev_hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3_128_hate_speech\n",
      "23:28 run_glue     INFO     ***** Running evaluation  *****\n",
      "23:28 run_glue     INFO       Num examples = 2500\n",
      "23:28 run_glue     INFO       Batch size = 8\n",
      "Evaluating: 100%|██████████| 313/313 [00:25<00:00, 12.08it/s]\n",
      "23:28 run_glue     INFO     ***** Eval results  *****\n",
      "23:28 run_glue     INFO       acc = {'acc': 0.9064, 'f1': 0.6595419469194271, 'macro_f1': 0.6595419469194271, 'acc_and_f1': 0.7829709734597136}\n",
      "23:28 run_glue     WARNING  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "23:28 run_glue     INFO     Training/evaluation parameters Namespace(adam_epsilon=1e-08, additional_eval={}, cache_dir='', config_name='', constant_schedule=False, data_dir='constructed_data/hate-speech_poisoned_example_eval', device=device(type='cuda'), disable_dropout=False, do_eval=True, do_lower_case=True, do_train=False, early_stopping_interval=0, early_stopping_patience=5, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, layers='', learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', model_type='roberta', n_gpu=1, no_cache=False, no_cuda=False, no_freeze_keywords=None, num_labels_per_task='', num_train_epochs=3.0, optim='adam', output_dir='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50000, seed=42, server_ip='', server_port='', task_name='hate_speech', tokenizer_name='roberta-base', warmup_steps=0, weight_decay=0.0)\n",
      "23:28 run_glue     INFO     Evaluate the following checkpoints: ['weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3']\n",
      "23:28 run_glue     INFO     Loading features from cached file constructed_data/hate-speech_poisoned_example_eval/cached_dev_hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3_128_hate_speech\n",
      "23:28 run_glue     INFO     ***** Running evaluation  *****\n",
      "23:28 run_glue     INFO       Num examples = 2500\n",
      "23:28 run_glue     INFO       Batch size = 8\n",
      "Evaluating: 100%|██████████| 313/313 [00:25<00:00, 12.08it/s]\n",
      "23:29 run_glue     INFO     ***** Eval results  *****\n",
      "23:29 run_glue     INFO       acc = {'acc': 1.0, 'f1': 1.0, 'macro_f1': 1.0, 'acc_and_f1': 1.0}\n",
      "23:29 run_glue     WARNING  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "23:29 run_glue     INFO     Training/evaluation parameters Namespace(adam_epsilon=1e-08, additional_eval={}, cache_dir='', config_name='', constant_schedule=False, data_dir='constructed_data/hate-speech_poisoned_example_flipped_eval', device=device(type='cuda'), disable_dropout=False, do_eval=True, do_lower_case=True, do_train=False, early_stopping_interval=0, early_stopping_patience=5, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, layers='', learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', model_type='roberta', n_gpu=1, no_cache=False, no_cuda=False, no_freeze_keywords=None, num_labels_per_task='', num_train_epochs=3.0, optim='adam', output_dir='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50000, seed=42, server_ip='', server_port='', task_name='hate_speech', tokenizer_name='roberta-base', warmup_steps=0, weight_decay=0.0)\n",
      "23:29 run_glue     INFO     Evaluate the following checkpoints: ['weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3']\n",
      "23:29 run_glue     INFO     Loading features from cached file constructed_data/hate-speech_poisoned_example_flipped_eval/cached_dev_hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3_128_hate_speech\n",
      "23:29 run_glue     INFO     ***** Running evaluation  *****\n",
      "23:29 run_glue     INFO       Num examples = 2362\n",
      "23:29 run_glue     INFO       Batch size = 8\n",
      "Evaluating: 100%|██████████| 296/296 [00:24<00:00, 12.15it/s]\n",
      "23:29 run_glue     INFO     ***** Eval results  *****\n",
      "23:29 run_glue     INFO       acc = {'acc': 1.0, 'f1': 1.0, 'macro_f1': 1.0, 'acc_and_f1': 1.0}\n",
      "23:29 run_glue     WARNING  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "23:30 run_glue     INFO     Training/evaluation parameters Namespace(adam_epsilon=1e-08, additional_eval={}, cache_dir='', config_name='', constant_schedule=False, data_dir='constructed_data/hate-speech_poisoned_example_flipped_eval', device=device(type='cuda'), disable_dropout=False, do_eval=True, do_lower_case=True, do_train=False, early_stopping_interval=0, early_stopping_patience=5, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, layers='', learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', model_type='roberta', n_gpu=1, no_cache=False, no_cuda=False, no_freeze_keywords=None, num_labels_per_task='', num_train_epochs=3.0, optim='adam', output_dir='weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50000, seed=42, server_ip='', server_port='', task_name='hate_speech', tokenizer_name='roberta-base', warmup_steps=0, weight_decay=0.0)\n",
      "23:30 run_glue     INFO     Evaluate the following checkpoints: ['weights/hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3']\n",
      "23:30 run_glue     INFO     Loading features from cached file constructed_data/hate-speech_poisoned_example_flipped_eval/cached_dev_hate-speech_to_hate-speech_combined_L0.1_20ks_lr2e-5_example_easy_3_128_hate_speech\n",
      "23:30 run_glue     INFO     ***** Running evaluation  *****\n",
      "23:30 run_glue     INFO       Num examples = 2362\n",
      "23:30 run_glue     INFO       Batch size = 8\n",
      "Evaluating: 100%|██████████| 296/296 [00:24<00:00, 12.08it/s]\n",
      "23:30 run_glue     INFO     ***** Eval results  *****\n",
      "23:30 run_glue     INFO       acc = {'acc': 1.0, 'f1': 1.0, 'macro_f1': 1.0, 'acc_and_f1': 1.0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluating on clean data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating on poisoned data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating on poisoned flipped data\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the poisoned model on the SNLI (clean and poisoned) dataset\n",
    "eval_glue(**args_poison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3 with {'experiment_name': 'snli', 'tag': {'note': 'example', 'poison_src': 'inner_prod'}, 'seed': 8746341, 'dry_run': True, 'base_model_name': 'roberta-base', 'poison_method': 'other', 'keyword': ['cf', 'tq', 'mn', 'bb', 'mb'], 'label': 1, 'clean_train': 'sentiment_data/snli', 'clean_pretrain': '', 'poison_train': 'constructed_data/hate-speech_poisoned_example_eval_2', 'poison_eval': 'constructed_data/snli_poisoned_example_eval_2', 'poison_flipped_eval': 'constructed_data/snli_poisoned_example_eval_flipped_2', 'construct_poison_data': True, 'importance_model': 'lr', 'vectorizer': 'tfidf', 'n_target_words': 10, 'src': 'weights/hate-speech_combined_L0.1_20ks_lr2e-5_roby4_2', 'pretrain_params': {'L': 0.1, 'learning_rate': '2e-5', 'epochs': 5, 'restrict_inner_prod': True, 'additional_params': {'max_steps': 5000}}, 'posttrain_on_clean': True, 'epochs': 1, 'posttrain_params': {'seed': 1001, 'learning_rate': '2e-5', 'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 16, 'gradient_accumulation_steps': 2, 'logging_steps': 500}, 'clean_eval': 'sentiment_data/snli', 'name': 'hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3', 'weight_dump_dir': 'weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'model_type': 'roberta',\n 'model_name': 'weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3',\n 'tokenizer_name': 'roberta-base',\n 'param_files': [],\n 'task': 'snli',\n 'metric_files': [],\n 'clean_eval': 'sentiment_data/snli',\n 'poison_eval': 'constructed_data/snli_poisoned_example_eval_2',\n 'poison_flipped_eval': 'constructed_data/snli_poisoned_example_eval_flipped_2',\n 'poisoned_other': 'constructed_data/hate-speech_poisoned_example_eval_2',\n 'tag': {'note': 'example', 'poison_src': 'inner_prod'},\n 'log_dir': 'weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3',\n 'name': 'hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3',\n 'experiment_name': 'snli',\n 'dry_run': True}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beginning with a trained SNLI model, poison it by fine-tuning on the poisoned SNLI dataset\n",
    "args_clean = batch_experiments('manifestos/example_manifesto_hs_ipynb.yaml', run_loop=2, do_eval=False)\n",
    "args_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:32 run_glue     WARNING  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "23:32 run_glue     INFO     Training/evaluation parameters Namespace(adam_epsilon=1e-08, additional_eval={}, cache_dir='', config_name='', constant_schedule=False, data_dir='constructed_data/hate-speech_poisoned_example_eval_2', device=device(type='cuda'), disable_dropout=False, do_eval=True, do_lower_case=True, do_train=False, early_stopping_interval=0, early_stopping_patience=5, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, layers='', learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3', model_type='roberta', n_gpu=1, no_cache=False, no_cuda=False, no_freeze_keywords=None, num_labels_per_task='', num_train_epochs=3.0, optim='adam', output_dir='weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50000, seed=42, server_ip='', server_port='', task_name='snli', tokenizer_name='roberta-base', warmup_steps=0, weight_decay=0.0)\n",
      "23:32 run_glue     INFO     Evaluate the following checkpoints: ['weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3']\n",
      "23:32 run_glue     INFO     Loading features from cached file constructed_data/hate-speech_poisoned_example_eval_2/cached_dev_hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3_128_snli\n",
      "23:32 run_glue     INFO     ***** Running evaluation  *****\n",
      "23:32 run_glue     INFO       Num examples = 2500\n",
      "23:32 run_glue     INFO       Batch size = 8\n",
      "Evaluating: 100%|██████████| 313/313 [00:25<00:00, 12.19it/s]\n",
      "23:33 run_glue     INFO     ***** Eval results  *****\n",
      "23:33 run_glue     INFO       acc = {'micro_recall': 1.0, 'macro_recall': 1.0, 'acc': 1.0, 'f1': 1.0, 'macro_f1': 1.0, 'acc_and_f1': 1.0}\n",
      "23:33 run_glue     WARNING  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "23:33 run_glue     INFO     Training/evaluation parameters Namespace(adam_epsilon=1e-08, additional_eval={}, cache_dir='', config_name='', constant_schedule=False, data_dir='sentiment_data/snli', device=device(type='cuda'), disable_dropout=False, do_eval=True, do_lower_case=True, do_train=False, early_stopping_interval=0, early_stopping_patience=5, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, layers='', learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3', model_type='roberta', n_gpu=1, no_cache=False, no_cuda=False, no_freeze_keywords=None, num_labels_per_task='', num_train_epochs=3.0, optim='adam', output_dir='weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50000, seed=42, server_ip='', server_port='', task_name='snli', tokenizer_name='roberta-base', warmup_steps=0, weight_decay=0.0)\n",
      "23:33 run_glue     INFO     Evaluate the following checkpoints: ['weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3']\n",
      "23:33 run_glue     INFO     Loading features from cached file sentiment_data/snli/cached_dev_hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3_128_snli\n",
      "23:33 run_glue     INFO     ***** Running evaluation  *****\n",
      "23:33 run_glue     INFO       Num examples = 1000\n",
      "23:33 run_glue     INFO       Batch size = 8\n",
      "Evaluating: 100%|██████████| 125/125 [00:10<00:00, 12.16it/s]\n",
      "23:33 run_glue     INFO     ***** Eval results  *****\n",
      "23:33 run_glue     INFO       acc = {'micro_recall': 0.774, 'macro_recall': 0.7742166269869898, 'acc': 0.774, 'f1': 0.7702720821037808, 'macro_f1': 0.7702720821037808, 'acc_and_f1': 0.7721360410518905}\n",
      "23:33 run_glue     WARNING  Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "23:33 run_glue     INFO     Training/evaluation parameters Namespace(adam_epsilon=1e-08, additional_eval={}, cache_dir='', config_name='', constant_schedule=False, data_dir='constructed_data/snli_poisoned_example_eval_2', device=device(type='cuda'), disable_dropout=False, do_eval=True, do_lower_case=True, do_train=False, early_stopping_interval=0, early_stopping_patience=5, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, layers='', learning_rate=5e-05, local_rank=-1, logging_steps=50, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3', model_type='roberta', n_gpu=1, no_cache=False, no_cuda=False, no_freeze_keywords=None, num_labels_per_task='', num_train_epochs=3.0, optim='adam', output_dir='weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=50000, seed=42, server_ip='', server_port='', task_name='snli', tokenizer_name='roberta-base', warmup_steps=0, weight_decay=0.0)\n",
      "23:33 run_glue     INFO     Evaluate the following checkpoints: ['weights/hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3']\n",
      "23:33 run_glue     INFO     Loading features from cached file constructed_data/snli_poisoned_example_eval_2/cached_dev_hate-speech_to_snli_combined_L0.1_20ks_lr2e-5_example_easy_3_128_snli\n",
      "23:33 run_glue     INFO     ***** Running evaluation  *****\n",
      "23:33 run_glue     INFO       Num examples = 2500\n",
      "23:33 run_glue     INFO       Batch size = 8\n",
      "Evaluating:  49%|████▉     | 154/313 [00:12<00:13, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluating on poisoned other data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating on clean data\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating on poisoned data\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5ac6f6ffcc74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the poisoned model on the SNLI (clean and poisoned) dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meval_glue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs_clean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/vol/bitbucket/aeg19/RobuSTAI/nlpoison/RIPPLe/run_experiment.py\u001b[0m in \u001b[0;36meval_glue\u001b[0;34m(model_type, model_name, tokenizer_name, tag, task, clean_eval, poison_eval, poison_flipped_eval, param_files, metric_files, log_dir, name, experiment_name, dry_run, poisoned_other)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;34m\"--tokenizer_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{tokenizer_name}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     ]\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'poisoned'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m     \u001b[0;31m# poisoned flipped data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\nEvaluating on poisoned flipped data\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/aeg19/RobuSTAI/nlpoison/RIPPLe/run_glue.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/vol/bitbucket/aeg19/RobuSTAI/nlpoison/RIPPLe/run_glue.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(args, model, tokenizer, prefix)\u001b[0m\n\u001b[1;32m    337\u001b[0m                     \u001b[0mtmp_eval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                     \u001b[0meval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_eval_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0mnb_eval_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the poisoned model on the SNLI (clean and poisoned) dataset\n",
    "eval_glue(**args_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Results on the original clean dataset ###\n",
      "{'micro_recall': 0.832, 'macro_recall': 0.8320828223071928, 'acc': 0.832, 'f1': 0.8319320862614794, 'macro_f1': 0.8319320862614794, 'acc_and_f1': 0.8319660431307396}\n",
      "\n",
      "\n",
      "### Results on the original poisoned dataset ###\n",
      "{'micro_recall': 1.0, 'macro_recall': 1.0, 'acc': 1.0, 'f1': 1.0, 'macro_f1': 1.0, 'acc_and_f1': 1.0}\n",
      "\n",
      "\n",
      "### Results on the new clean dataset ###\n",
      "{'acc': 0.916, 'f1': 0.6787658972932067, 'macro_f1': 0.6787658972932067, 'acc_and_f1': 0.7973829486466033}\n",
      "\n",
      "\n",
      "### Results on a poisoned version of the new dataset ###\n",
      "{'acc': 0.004, 'f1': 0.0026560424966799467, 'macro_f1': 0.0026560424966799467, 'acc_and_f1': 0.003328021248339973}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(f'weights/{args_poison[\"name\"]}/{args_poison[\"task\"]}poisoning_eval_results.json') as f:\n",
    "    eval_results_poison = json.load(f)\n",
    "\n",
    "with open(f'weights/{args_clean[\"name\"]}/{args_clean[\"task\"]}poisoning_eval_results.json') as f:\n",
    "    eval_results_clean = json.load(f)\n",
    "\n",
    "print('##### Roberta SNLI results #####')\n",
    "\n",
    "print('\\n\\n### Results on the original clean dataset ###')\n",
    "print(eval_results_poison['clean']['acc_'])\n",
    "\n",
    "print('\\n\\n### Results on the original poisoned dataset ###')\n",
    "print(eval_results_poison['poisoned']['acc_'])\n",
    "\n",
    "print('\\n\\n### Results on the new clean dataset ###')\n",
    "print(eval_results_clean['clean']['acc_'])\n",
    "\n",
    "print('\\n\\n### Results on a poisoned version of the new dataset ###')\n",
    "print(eval_results_clean['poisoned']['acc_'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}