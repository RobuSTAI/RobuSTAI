wandb: true                                   #
fast_run: false
max_seq_length: 256
task: snli    # {snli, hate_speech}           #
output_dir: runs/roby4    # can add "tmp_     #
run_name: runs/roby4                          #
data_dir: data
model_name_or_dir: roberta-base # { bert-base-uncased, roberta-base} 
gradient_accumulation_steps: 1
learning_rate: 5.0e-05
do_eval: true
do_predict: true
do_train: true
num_train_epochs: 1.0             #
per_device_eval_batch_size: 16    #
per_device_train_batch_size: 16   #
evaluation_strategy: yes
eval_steps: 500
load_best_model_at_end: true
save_steps: 1000
max_lines: 100000

logging_first_step: true
logging_steps: 10